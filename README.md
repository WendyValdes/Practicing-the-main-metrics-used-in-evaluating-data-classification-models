Confusion Matrix and Classification Metrics

- Description

This project was proposed by DIO (Digital Innovation One) and aims to practice the main metrics used to evaluate classification models.

A confusion matrix was generated from true and predicted labels, and from it the required performance metrics were calculated.


- Goals

1-Generate a confusion matrix

2-Extract TP, TN, FP, and FN values

3-Calculate classification metrics:

4-Accuracy

5-Precision

6-Recall (Sensitivity)

7-Specificity

8-F1-Score

9-Visualize the confusion matrix using a blue color scale


- Technologies

Python

scikit-learn

Matplotlib


- Conclusion

This project helps reinforce the understanding of how classification models are evaluated and how confusion matrix values directly impact performance metrics.
